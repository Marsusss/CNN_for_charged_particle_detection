{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#File names and folders\n",
    "MinBiasdir = \"minbiasdir06-05\\\\\" # MB folder name\n",
    "MinBiastrainfilename = \"minbias_train.h5\" # MB train test and validation name\n",
    "MinBiastestfilename = \"minbias_test.h5\"\n",
    "MinBiasvalidfilename = \"minbias_valid.h5\"\n",
    "MinBiasvalidptestfilename = \"minbias_valid_p_test.h5\" # Valid and test set added together for larger set\n",
    "\n",
    "LoneMuondir = \"lonemuondir06-05\\\\\" # Same for LM\n",
    "LoneMuontrainfilename = \"lone_muon_train_new.h5\"\n",
    "LoneMuontestfilename = \"lone_muon_test_new.h5\"\n",
    "LoneMuonvalidfilename = \"lone_muon_valid_new.h5\"\n",
    "LoneMuonvalidptestfilename = \"lone_muon_valid_p_test_13-10_new.h5\"\n",
    "\n",
    "\n",
    "#Starting parameters\n",
    "nSl = 6 # Number of slices\n",
    "nL = 8\n",
    "\n",
    "nbinsphi0 = 216+2*6 #phi-bins\n",
    "nbinsQOpT = 216+2*2 #pT-bins\n",
    "\n",
    "size_x = nbinsphi0\n",
    "size_y = nbinsQOpT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the files\n",
    "\n",
    "#Train HDF5 file\n",
    "MinBiastrainstorage = pd.HDFStore(MinBiasdir + MinBiastrainfilename)\n",
    "LoneMuontrainstorage = pd.HDFStore(LoneMuondir + LoneMuontrainfilename)\n",
    "\n",
    "#Train key list to file\n",
    "Minbiastrainlist = MinBiastrainstorage.keys()\n",
    "LoneMuontrainlist = LoneMuontrainstorage.keys()\n",
    "\n",
    "#Length of lists\n",
    "nMinbiastrainlist = len(Minbiastrainlist)\n",
    "nLoneMuontrainlist = len(LoneMuontrainlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MinBiasvalidstorage = pd.HDFStore(MinBiasdir + MinBiasvalidfilename)\n",
    "LoneMuonvalidstorage = pd.HDFStore(LoneMuondir + LoneMuonvalidfilename)\n",
    "\n",
    "Minbiasvalidlist = MinBiasvalidstorage.keys()\n",
    "LoneMuonvalidlist = LoneMuonvalidstorage.keys()\n",
    "\n",
    "nMinbiasvalidlist = len(Minbiasvalidlist)\n",
    "nLoneMuonvalidlist = len(LoneMuonvalidlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MinBiasteststorage = pd.HDFStore(MinBiasdir + MinBiastestfilename)\n",
    "LoneMuonteststorage = pd.HDFStore(LoneMuondir + LoneMuontestfilename)\n",
    "\n",
    "Minbiastestlist = MinBiasteststorage.keys()\n",
    "LoneMuontestlist = LoneMuonteststorage.keys()\n",
    "\n",
    "nMinbiastestlist = len(Minbiastestlist)\n",
    "nLoneMuontestlist = len(LoneMuontestlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MinBiasvalidpteststorage = pd.HDFStore(MinBiasdir + MinBiasvalidptestfilename)\n",
    "LoneMuonvalidpteststorage = pd.HDFStore(LoneMuondir + LoneMuonvalidptestfilename)\n",
    "\n",
    "Minbiasvalidptestlist = MinBiasvalidpteststorage.keys()\n",
    "LoneMuonvalidptestlist = LoneMuonvalidpteststorage.keys()\n",
    "\n",
    "nMinbiasvalidptestlist = len(Minbiasvalidptestlist)\n",
    "nLoneMuonvalidptestlist = len(LoneMuonvalidptestlist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(storage, keys, i):\n",
    "    batch = storage[keys[i]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_allslices(df):\n",
    "    n_events = int(len(df.index)/nSl/nL)\n",
    "    \n",
    "    images = torch.empty(0,nSl,nL,nbinsQOpT,nbinsphi0, dtype = torch.int)\n",
    "    for i in range(n_events):\n",
    "        slices = torch.empty(0,nL,nbinsQOpT,nbinsphi0, dtype = torch.int)\n",
    "        for j in range(nSl):\n",
    "            layers = torch.empty(0,nbinsQOpT,nbinsphi0, dtype = torch.int)\n",
    "            for k in range(nL):\n",
    "                layer = torch.zeros((nbinsQOpT,nbinsphi0), dtype = torch.int)\n",
    "                layerx = df['x_pos'].iloc[i*nSl*nL + j*nL + k]\n",
    "                layery = df['y_pos'].iloc[i*nSl*nL + j*nL + k]\n",
    "                value = df['value'].iloc[i*nSl*nL + j*nL + k]\n",
    "                layerxnp = ak.to_numpy(layerx).astype(int)\n",
    "                layerynp = ak.to_numpy(layery).astype(int)\n",
    "                valuenp = ak.to_numpy(value).astype(int)\n",
    "                layer[layerynp,layerxnp] = torch.from_numpy(valuenp)\n",
    "\n",
    "                layers = torch.cat((layers, layer.unsqueeze(0)),0)\n",
    "\n",
    "            slices = torch.cat((slices, layers.unsqueeze(0)),0)\n",
    "    \n",
    "        images = torch.cat((images, slices.unsqueeze(0)),0)\n",
    "                \n",
    "    return images\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_center_2_all_slices(image):\n",
    "    summedimage = torch.sum(image.gt(0),2)\n",
    "    batchlist = []\n",
    "    for ievent, event in enumerate(summedimage):\n",
    "        imagemax = torch.max(event)\n",
    "#         eventlist = []\n",
    "#         print(\"max:\",imagemax)\n",
    "#         if imagemax >= 6:\n",
    "        for islice, slice in enumerate(event):\n",
    "            slicelist = []\n",
    "            slicemax = torch.max(slice)\n",
    "            if slicemax >= 6:\n",
    "                for q in range(nbinsQOpT):\n",
    "                    for phi in range(nbinsphi0):\n",
    "                        if slice[q,phi] == slicemax:\n",
    "                            slicelist += [[q,phi]]\n",
    "#                             print(\"point added\")\n",
    "#                             print(eventlist)\n",
    "\n",
    "            else:\n",
    "                slicelist += []\n",
    "#             print(\"empty\")\n",
    "#             print(eventlist)\n",
    "\n",
    "            batchlist += [slicelist]\n",
    "            \n",
    "#         print(eventlist)\n",
    "            \n",
    "#     print(batchlist)\n",
    "    newlist = []\n",
    "    \n",
    "    for islice, slice in enumerate(batchlist):\n",
    "#         print(event)\n",
    "        if len(slice)>0:\n",
    "            torchslice = torch.tensor(slice)\n",
    "            meanval = torch.mean(torchslice.float(),0)\n",
    "            if (meanval[0] >= 1 - 0.5) and (meanval[0] <= (nbinsQOpT - 1) - 1 - 0.5) and (meanval[1] >= 2 - 0.5) and (meanval[1] <= (nbinsphi0 - 1) - 2 - 0.5):\n",
    "                itrueevent = int(islice/nSl)\n",
    "                itrueslice = islice - itrueevent*nSl\n",
    "                slicemax = torch.max(summedimage[itrueevent, itrueslice])\n",
    "\n",
    "                p0 = int(meanval[0]+1/2)\n",
    "                p1 = int(meanval[1]+1/2)\n",
    "\n",
    "    #             vicinity = torch.zeros(3,3)\n",
    "    #             p1min = max(p1 - 2, 0)\n",
    "    #             p1max = min(p1 + 3, nbinsphi0)\n",
    "    #             p0min = max(p0 - 2, 0)\n",
    "    #             p0max = min(p0 + 3, nbinsQOpT)\n",
    "    #             vicinity[p0min - (p0 - 2):5 - (p0max - (p0 + 3)), p1min - (p1 - 2):5 - (p1max - (p1 + 3))] = summedimage[ievent, 0, p0min:p0max, p1min:p1max]\n",
    "\n",
    "    #             vicp0min = vicinity\n",
    "\n",
    "    #             p0lowerbound = 0 + 2 + 1\n",
    "    #             p1lowerbound = 0 + 2 + 2\n",
    "    #             p0upperbound = (nbinsQOpT - 1) - 2 - 1\n",
    "    #             p1upperbound = (nbinsphi0 - 1) - 2 - 2\n",
    "                p0lowerbound = 0 + 1\n",
    "                p1lowerbound = 0 + 2\n",
    "                p0upperbound = (nbinsQOpT - 1) - 1\n",
    "                p1upperbound = (nbinsphi0 - 1) - 2\n",
    "\n",
    "                p0min1 = max(p0 - 1, p0lowerbound)\n",
    "                p1min1 = max(p1 - 2, p1lowerbound)\n",
    "                p0max1 = min(p0 + 2, p0upperbound)\n",
    "                p1max1 = min(p1 + 3, p1upperbound)\n",
    "\n",
    "                vicinity1 = summedimage[itrueevent, itrueslice, p0min1:p0max1, p1min1:p1max1]\n",
    "                sufficients = vicinity1.eq(slicemax)\n",
    "                if torch.sum(sufficients) > 0:\n",
    "                    \n",
    "                \n",
    "                    print(vicinity1)\n",
    "#                     p1pltmin = max(p1 - 10, 0)\n",
    "#                     p1pltmax = min(p1 + 10, nbinsphi0 - 1)\n",
    "#                     p0pltmin = max(p0 - 10, 0)\n",
    "#                     p0pltmax = min(p0 + 10, nbinsQOpT - 1)\n",
    "#                     plt.imshow(summedimage[itrueevent, 0, p0pltmin:p0pltmax, p1pltmin:p1pltmax])\n",
    "#                     plt.show()\n",
    "#                     plt.imshow(summedimage[i, 0, p1 - 10:p1 + 10, p0 - 10:p0 + 10])\n",
    "\n",
    "                    steepness_along = 2*vicinity1 - (summedimage[itrueevent, itrueslice, p0min1 - 1:p0max1 - 1, p1min1 - 2:p1max1 - 2]\n",
    "                                                     + summedimage[itrueevent, itrueslice, p0min1 + 1:p0max1 + 1, p1min1 + 2:p1max1 + 2])\n",
    "\n",
    "                    steepness_across = 2*vicinity1 - (summedimage[itrueevent, itrueslice, p0min1 - 1:p0max1 - 1, p1min1 + 1:p1max1 + 1]\n",
    "                                                     + summedimage[itrueevent, itrueslice, p0min1 + 1:p0max1 + 1, p1min1 - 1:p1max1 - 1])\n",
    "\n",
    "\n",
    "                    indices = torch.nonzero(sufficients)\n",
    "\n",
    "                    score = - steepness_along + 0.01*steepness_across\n",
    "\n",
    "                    best = torch.argmax(score[sufficients])\n",
    "\n",
    "                    bestpoint = indices[best]\n",
    "\n",
    "        #             if torch.max(summedimage[ievent]) == summedimage[ievent, 0, int(meanval[0]+1/2), int(meanval[1]+1/2)]: #Only implemented for 1 slice!!!!\n",
    "                    \n",
    "                    newlist += [[itrueevent, itrueslice, bestpoint[0] + p0min1, bestpoint[1] + p1min1]]\n",
    "                \n",
    "                else:\n",
    "                    print(slicemax)\n",
    "                    print(vicinity1)\n",
    "        \n",
    "    return slicelist, newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that this should be done for every train test and validation file you wanna use.\n",
    "path = LoneMuondir\n",
    "newfile = \"lone_muon_valid_p_test_13-10_new.h5\" #insert own file names\n",
    "newstorage = pd.HDFStore(LoneMuondir + newfile)\n",
    "oldfile = \"lone_muon_valid_p_test_13-10.h5\" #insert own file names\n",
    "old_storage = pd.HDFStore(LoneMuondir + oldfile) #Opens storages\n",
    "old_list = old_storage.keys() #Gets keys\n",
    "nlist = len(old_list) #Number of mini batches\n",
    "for i in range(nlist):\n",
    "    print(i,nlist)\n",
    "    LMpd = get_batch(old_storage, old_list, i) #Load batch i\n",
    "    LM = get_images_allslices(LMpd) #Get LM image\n",
    "    something, LMtruth_1 = get_max_center_2_all_slices(LM) #Get truth\n",
    "    LMpd2 = LMpd[LMpd.columns[0:3]].copy() #tabel copy\n",
    "    nrows = len(LMpd2.index)\n",
    "    LMpd2['truth_qOpT'] = -np.ones(nrows) #Adds truth collumn\n",
    "    LMpd2['truth_phi0'] = -np.ones(nrows)\n",
    "    \n",
    "    for element in LMtruth_1:\n",
    "        print(element)\n",
    "        idx0 = LMpd2.index[0]\n",
    "        LMpd2.at[idx0 + element[0]*nSl*nL + element[1]*nL,'truth_qOpT'] = element[2] #Adds truth\n",
    "        LMpd2.at[idx0 + element[0]*nSl*nL + element[1]*nL,'truth_phi0'] = element[3]\n",
    "        \n",
    "    newstorage[old_list[i]] = LMpd2 #Saves mini batch\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
